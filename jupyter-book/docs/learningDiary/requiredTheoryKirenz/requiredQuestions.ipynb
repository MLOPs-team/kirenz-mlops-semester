{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes: Required questions - theory Kirenz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-centric AI\n",
    "\n",
    "Notes on the video of AI pioneer Andrew Ng:\"A Chat with Andrew on MLOps: From Model-centric to Data-centric AI\".\n",
    "\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/06-AZXmwHjo\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
    "\n",
    "\n",
    "- **AI-System** = Code (model/algorithm) + Data \n",
    "\n",
    "- Data is food for AI  \n",
    "![image](../../../assets/img/dataIsFood.png)     \n",
    "\n",
    "- It's very important especially for small data sets that the labels are consistencly  \n",
    "![image](../../../assets/img/smallDataAndLabelConsistency.png)  \n",
    "\n",
    "    - **Noisy Dataset**: data that contains a large amount of additional meaningless information. E.g. corrupted data...all data that cannot be understood and interpreted  by a user system.\n",
    "    \n",
    "    - **Noisy labels**: labels that were set incorrectly or inconsitently  \n",
    "\n",
    "\n",
    "- **Theory: Clean vs. noisy Data**  \n",
    "    You have 500 Examples and 12% of the examples are noisy (incorrectly or inconsitently labeld)\n",
    "\n",
    "    The following are about equally effective: \n",
    "        - Clean up the noise => 60 examples\n",
    "        - Collect annother 500 new examples (double the training set)\n",
    "    \n",
    "    With a data centric view, there is significant of room for improvment in problems <10.000 examples\n",
    "\n",
    "```{admonition} Required questions\n",
    ":class: tip\n",
    "- **Describe the lifecycle of an ML project**\n",
    "\n",
    "    ![image](../../../assets/img/LifecycleMlProject.png)  \n",
    "\n",
    "    - **Collect data**\n",
    "        Define and collect the data. It's important that the data is labeled consistently. \n",
    "\n",
    "         ![image](../../../assets/img/iguanaDetection.png)  \n",
    "\n",
    "         All 3 options are fine, but we should label the whole dataset in one way. For example...we label all the data as in the first picture\n",
    "\n",
    "         Ho can we make data quality systematic in MLOps?\n",
    "         - Ask two independent labelers to label a sample of images\n",
    "         - Measure consistency between labelers to discover where they disagree\n",
    "         - For clases where the labelers disagree, revise the labeling instruction until they become consistent\n",
    "\n",
    "    - **Train model**\n",
    "        It's important that after ech training we analyze what the error was. \n",
    "\n",
    "        Making it systemtic - iteratively improving the data (Data-centric view)\n",
    "        - Train a model\n",
    "        - Error the analysis to identify the types of data the algorithm does poorly on (e.g. speech with car noise).\n",
    "          *Example: Speech with car nois in background. If that's the problem, we should collect more data with speech in background.Not just add 5000 more data, but specifically data with speech and car noise in the background  --> Model can be significantly improved by selectively adding datan*\n",
    "        - Either get more of that data via data augmentation, data generation or data collection (change inputs x) or give more consistent definition for labels if they were found to be ambiguous (change labels y)\n",
    "\n",
    "____________________________\n",
    "\n",
    "- **What is the difference between a model-centric vs data-centric view**  \n",
    "  \n",
    "    **Model-centric view**  \n",
    "    Collect what data you can, and develop a model good enough to deal with the noise in the data.  \n",
    "\n",
    "    Hold the data fixed and iteratively improve the code/model.  \n",
    "      \n",
    "    **Data-centric view**  \n",
    "    The consistency of the data is paramount. Use tools to improve the data quality; this will allow multiple models to do well.  \n",
    "\n",
    "    Hold the code fixed and iteratively improve the data..  \n",
    "____________________________\n",
    "\n",
    "- **Describe MLOps’ most important task**  \n",
    "  \n",
    "    Ensure consistently high-quality data in all phases oft he ML project lifecycle        \n",
    "    What is good Data?\n",
    "    - Defined consistently (definition of labels y is unambiguous)\n",
    "    - Cover of important cases (good coverage of inputs x)\n",
    "    - Enough data – for example enough data of speech with car noise in background\n",
    "    - Has timely feedback from production data (distribution covers data drift and concept drift)\n",
    "    - Sized appropriately\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common MLOps related challenges\n",
    "\n",
    "Notes on the video of Nayur Khan, global head of technical delivery at McKinsey\n",
    "\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/M1F0FDJGu0Q\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
    "\n",
    "```{admonition} Required questions\n",
    ":class: tip\n",
    "- **Describe 4 typical challenges when creating machine learning products.**  \n",
    "    \n",
    "    What we typically find is that a couple of teams sitting in the same office or sometimes geographically separated and many problems result….  \n",
    "    \n",
    "    - *Lack of collaboration* or sharing of components/libaries betwenn the teams but even within the same team. \n",
    "    - *Inconsistency*: Different approachtes to solving same problem, or using inonsistent data or algortihms\n",
    "    - *Duplicaton*: Reinveting the wheel. Teams sitting next to each other and try to solve the same problem. \n",
    "    - *Tech Debt*: Large codebases and tech debt. You don't know how to maintain your code\n",
    "\n",
    "\n",
    "____________________________\n",
    "\n",
    "- **Reusability concerns within a codebase: Explain a common way to look at what code is doing in a typical ML project.**  \n",
    "  \n",
    "____________________________\n",
    "\n",
    "- **What kind of problems does the open-source framework Kedro solve and where does Kedro fit in the MLOps ecosystem?**  \n",
    "  \n",
    "    Kedro solved to problem of maintability.   \n",
    "\n",
    "    Kedro is not for the deployment. Kedro focuses on how you work while writing standardized, modular, maintaible and reproducible data sience code and does not focus on how you would like to run it in production. The responsibility of „What time will this pipeline run?\" and \"How will i know if it failed?\" is left to tools called orchestrators like Apache Airflow, Luigi, Dagster and Perfect. Orchestrators do not focus on the process of producing something that could be deployed, which is what Kedro does. \n",
    "\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components \n",
    "\n",
    "Next, you’ll get an overview about some of the primary components of MLOps. “An introduction to MLOps on Google Cloud” by Nate Keating:\n",
    "\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/6gdrwFMaEZ0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
    "\n",
    "```{admonition} Required questions\n",
    ":class: tip\n",
    "- **Describe the challenges of current ML systems (where are teams today)?**  \n",
    "    \n",
    "____________________________\n",
    "\n",
    "- **What are the components of the ML solution lifecycle?**  \n",
    "  \n",
    "____________________________\n",
    "\n",
    "- **Explain the steps in an automated E2E pipeline.**  \n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framework\n",
    "\n",
    "```{admonition} Required questions\n",
    ":class: tip\n",
    "- **Describe the difference betweeen DevOps versus MLOps**  \n",
    "    DevOps is a popular practice in developing and operating large-scale software systems. This practice provides benefits such as shortening the development cycles, increasing deployment velocity, and dependable releases. To achieve these benefits, you introduce two concepts in the software system development:\n",
    "        - *Continuous Integration (CI)*\n",
    "        - *Continuous Delivery (CD)*\n",
    "\n",
    "    An ML system is a software system, so similar practices apply to help guarantee that you can reliably build and operate ML systems at scale.\n",
    "    However, ML systems differ from other software systems in the following ways:**\n",
    "        - Team skills : In an ML project, the team usually includes data scientists or ML researchers, who focus on exploratory data analysis, model development, and experimentation. These members might not be experienced software engineers who can build production-class services.\n",
    "        - Development: ML is experimental in nature. You should try different features, algorithms, modeling techniques, and parameter configurations to find what works best for the problem as quickly as possible. The challenge is tracking what worked and what didn't, and maintaining reproducibility while maximizing code reusability.*\n",
    "        - Testing: Testing an ML system is more involved than testing other software systems. In addition to typical unit and integration tests, you need data validation, trained model quality evaluation, and model validation.\n",
    "        - Deployment: In ML systems, deployment isn't as simple as deploying an offline-trained ML model as a prediction service. ML systems can require you to deploy a multi-step pipeline to automatically retrain and deploy model. This pipeline adds complexity and requires you to automate steps that are manually done before deployment by data scientists to train and validate new models.\n",
    "        - Production: ML models can have reduced performance not only due to suboptimal coding, but also due to constantly evolving data profiles. In other words, models can decay in more ways than conventional software systems, and you need to consider this degradation. Therefore, you need to track summary statistics of your data and monitor the online performance of your model to send notifications or roll back when values deviate from your expectations.\n",
    "\n",
    "    ML and other software systems are similar in continuous integration of source control, unit testing, integration testing, and continuous delivery of the software module or the package. However, in ML, there are a few notable differences:\n",
    "        - CI is no longer only about testing and validating code and components, but also testing and validating data, data schemas, and models.\n",
    "        - CD is no longer about a single software package or a service, but a system (an ML training pipeline) that should automatically deploy another service (model prediction service).\n",
    "        - CT is a new property, unique to ML systems, that's concerned with automatically retraining and serving the models\n",
    "____________________________\n",
    "\n",
    "- **Name and explain the steps for developing ML models**  \n",
    "\n",
    "1.\tData extraction: You select and integrate the relevant data from various data sources for the ML task.\n",
    "2.\tData analysis: You perform exploratory data analysis (EDA) to understand the available data for building the ML model. This process leads to the following:\n",
    "    - Understanding the data schema and characteristics that are expected by the model.\n",
    "    - Identifying the data preparation and feature engineering that are needed for the model.\n",
    "3.\tData preparation: The data is prepared for the ML task. This preparation involves data cleaning, where you split the data into training, validation, and test sets. You also apply data transformations and feature engineering to the model that solves the target task. The output of this step are the data splits in the prepared format.\n",
    "4.\tModel training: The data scientist implements different algorithms with the prepared data to train various ML models. In addition, you subject the implemented algorithms to hyperparameter tuning to get the best performing ML model. The output of this step is a trained model.\n",
    "5.\tModel evaluation: The model is evaluated on a holdout test set to evaluate the model quality. The output of this step is a set of metrics to assess the quality of the model.\n",
    "6.\tModel validation: The model is confirmed to be adequate for deployment—that its predictive performance is better than a certain baseline.\n",
    "7.\tModel serving: The validated model is deployed to a target environment to serve predictions. This deployment can be one of the following:\n",
    "    - Microservices with a REST API to serve online predictions.\n",
    "    - An embedded model to an edge or mobile device.\n",
    "    - Part of a batch prediction system.\n",
    "8.\tModel monitoring: The model predictive performance is monitored to potentially invoke a new iteration in the ML process.\n",
    "\n",
    "____________________________\n",
    "\n",
    "- **Explain the steps in an automated E2E pipeline.**  \n",
    "tbd.\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
